{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Farfetech case study\n",
    "\n",
    "Product description generation.\n",
    "\n",
    "The object of this script is using deep learning technologies (CNN, LSTM) for product description generation.\n",
    "\n",
    "- Author: Kai Chen\n",
    "- Date: Apr, 2018\n",
    "\n",
    "\n",
    "### Reference\n",
    "- https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import operator\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import callbacks, applications, optimizers\n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Define the file paths\n",
    "\n",
    "PRODUCT_CSV_FILE = 'data/products.csv'\n",
    "ATTRIBUTE_CSV_FILE = 'data/attributes.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: read and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Description</th>\n",
       "      <th>DescriptionDate</th>\n",
       "      <th>SeasonOriginal</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Family</th>\n",
       "      <th>Category</th>\n",
       "      <th>ArticlePhotoId</th>\n",
       "      <th>CreateDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11295277</td>\n",
       "      <td>VIPE6CE-169953MCC 38NO</td>\n",
       "      <td>2016-01-07 13:13:09.527</td>\n",
       "      <td>SS15</td>\n",
       "      <td>Celine Black Phantom Bag</td>\n",
       "      <td>CELINE COLLARD</td>\n",
       "      <td>WOMEN</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Tote Bags</td>\n",
       "      <td>6129459</td>\n",
       "      <td>2016-01-07 13:10:46.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11292059</td>\n",
       "      <td>Grey  cotton 'Skip' crewneck from S.N.S. Herni...</td>\n",
       "      <td>2016-01-08 14:45:59.673</td>\n",
       "      <td>SS16</td>\n",
       "      <td>'Skip' crewneck</td>\n",
       "      <td>S.N.S. HERNING</td>\n",
       "      <td>MEN</td>\n",
       "      <td>GREY</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Sweaters &amp; Knitwear</td>\n",
       "      <td>6156126</td>\n",
       "      <td>2016-01-04 19:52:05.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11290981</td>\n",
       "      <td>Multicolour cotton 'Pak’r Tatenda' backpack fr...</td>\n",
       "      <td>2016-01-11 19:27:45.330</td>\n",
       "      <td>SS16</td>\n",
       "      <td>'Pakr Tatenda' backpack</td>\n",
       "      <td>EASTPAK</td>\n",
       "      <td>UNISEX</td>\n",
       "      <td>YELLOW &amp; ORANGE</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Backpacks</td>\n",
       "      <td>6216609</td>\n",
       "      <td>2016-01-03 15:21:20.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11293179</td>\n",
       "      <td>Ivory white and black hemp-cotton blend 'Honey...</td>\n",
       "      <td>2016-01-13 11:33:11.150</td>\n",
       "      <td>SS16</td>\n",
       "      <td>'Honey' wide brim hat</td>\n",
       "      <td>EUGENIA KIM</td>\n",
       "      <td>WOMEN</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Hats</td>\n",
       "      <td>6199465</td>\n",
       "      <td>2016-01-05 18:08:57.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11293099</td>\n",
       "      <td>Ivory white cotton embroidered lace frilled dr...</td>\n",
       "      <td>2016-01-13 15:22:08.247</td>\n",
       "      <td>SS16</td>\n",
       "      <td>embroidered lace frilled dress</td>\n",
       "      <td>RED VALENTINO</td>\n",
       "      <td>WOMEN</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>6173011</td>\n",
       "      <td>2016-01-05 16:55:35.427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductId                                        Description  \\\n",
       "0   11295277                             VIPE6CE-169953MCC 38NO   \n",
       "1   11292059  Grey  cotton 'Skip' crewneck from S.N.S. Herni...   \n",
       "2   11290981  Multicolour cotton 'Pak’r Tatenda' backpack fr...   \n",
       "3   11293179  Ivory white and black hemp-cotton blend 'Honey...   \n",
       "4   11293099  Ivory white cotton embroidered lace frilled dr...   \n",
       "\n",
       "           DescriptionDate SeasonOriginal                     ProductName  \\\n",
       "0  2016-01-07 13:13:09.527           SS15        Celine Black Phantom Bag   \n",
       "1  2016-01-08 14:45:59.673           SS16                 'Skip' crewneck   \n",
       "2  2016-01-11 19:27:45.330           SS16        'Pakr Tatenda' backpack   \n",
       "3  2016-01-13 11:33:11.150           SS16           'Honey' wide brim hat   \n",
       "4  2016-01-13 15:22:08.247           SS16  embroidered lace frilled dress   \n",
       "\n",
       "            Brand  Gender           Colour       Family             Category  \\\n",
       "0  CELINE COLLARD   WOMEN            BLACK         Bags            Tote Bags   \n",
       "1  S.N.S. HERNING     MEN             GREY     Clothing  Sweaters & Knitwear   \n",
       "2         EASTPAK  UNISEX  YELLOW & ORANGE         Bags            Backpacks   \n",
       "3     EUGENIA KIM   WOMEN            WHITE  Accessories                 Hats   \n",
       "4   RED VALENTINO   WOMEN            WHITE     Clothing              Dresses   \n",
       "\n",
       "   ArticlePhotoId               CreateDate  \n",
       "0         6129459  2016-01-07 13:10:46.507  \n",
       "1         6156126  2016-01-04 19:52:05.203  \n",
       "2         6216609  2016-01-03 15:21:20.480  \n",
       "3         6199465  2016-01-05 18:08:57.317  \n",
       "4         6173011  2016-01-05 16:55:35.427  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12631, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_product = pd.read_csv(PRODUCT_CSV_FILE)\n",
    "\n",
    "display(df_product.head(5))\n",
    "display(df_product.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of products 12631 in the csv file\n"
     ]
    }
   ],
   "source": [
    "list_product_id_df = df_product['ProductId'].unique()\n",
    "list_product_id_df = np.array(list_product_id_df)\n",
    "\n",
    "print('number of products {} in the csv file'.format(list_product_id_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with key: photo id -> value: product id\n",
    "# Note one photo belongs only to one product\n",
    "\n",
    "list_photo_id = df_product['ArticlePhotoId'].unique()\n",
    "\n",
    "dict_photo_product_id = dict()\n",
    "\n",
    "for photo_id in list_photo_id:\n",
    "    dict_photo_product_id[photo_id] = df_product[df_product['ArticlePhotoId']==photo_id]['ProductId'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of products: 12436\n"
     ]
    }
   ],
   "source": [
    "# Update the list_product_id, such that each product should have an image\n",
    "\n",
    "list_product_id = []\n",
    "\n",
    "# img_width, img_height = 100, 100\n",
    "# img_dir_path = \"data/images_{}_{}/\".format(img_width, img_height)\n",
    "# img_width, img_height = 100, 100\n",
    "img_dir_path = \"data/images/\"\n",
    "\n",
    "dirs = os.listdir(img_dir_path)\n",
    "\n",
    "for file_name in dirs:\n",
    "    file_path = os.path.join(img_dir_path, file_name)\n",
    "    product_id = int(file_name.split('_')[0])\n",
    "\n",
    "    if not product_id in list_product_id_df:\n",
    "        print('photo {} does not have product information'.format(file_path))\n",
    "    else:\n",
    "        list_product_id.append(product_id)\n",
    "    \n",
    "# print(list_product_id)\n",
    "print('number of products: {}'.format(len(list_product_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: image data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('preparing the image data ...')\n",
    "\n",
    "# extract VGG16 features\n",
    "def extract_features(dict_product_img):\n",
    "    # model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, nb_channel))\n",
    "    model = applications.VGG16()\n",
    "    model.layers.pop()\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "    print(model.summary())\n",
    "    features = dict()\n",
    "    for product_id, img in dict_product_img.items():\n",
    "        feature = model.predict(img, verbose=0)\n",
    "        features[product_id] = feature\n",
    "\n",
    "    return features\n",
    "\n",
    "# Create a dictionary with\n",
    "# key: product id, value: image\n",
    "dict_product_img = dict()\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "img_dir_path = \"data/images/\"\n",
    "dirs = os.listdir(img_dir_path)\n",
    "\n",
    "product_image_feature_file_path = 'product-vgg-features.pkl'\n",
    "\n",
    "for file_name in dirs:\n",
    "    file_path = os.path.join(img_dir_path, file_name)\n",
    "\n",
    "    # img = load_img(file_path)         \n",
    "    img = load_img(file_path, target_size=(img_width, img_height))   # this is a PIL image\n",
    "    x = img_to_array(img)                                            # this is a Numpy array with shape (img_width, img_height, 3)\n",
    "    x = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))           # this is a Numpy array with shape (1, 3, img_width, img_height)\n",
    "    # x = x.reshape((1,) + x.shape)                                  \n",
    "    # prepare the image for the VGG model\n",
    "    x = preprocess_input(x)\n",
    "    product_id = int(file_name.split('_')[0])\n",
    "\n",
    "    if not int(product_id) in list_product_id:\n",
    "        print('photo {} does not have product information'.format(file_path))\n",
    "    else:\n",
    "        dict_product_img[product_id] = x\n",
    "\n",
    "for product_id in list_product_id_df:\n",
    "    if product_id not in dict_product_img:\n",
    "        print('product {} does not have an image'.format(product_id))\n",
    "\n",
    "# extract VGG16 features\n",
    "dict_product_img_features = extract_features(dict_product_img)\n",
    "# save the features to file\n",
    "dump(dict_product_img_features, open(product_image_feature_file_path, 'wb'))\n",
    "\n",
    "print('save product image features to {}'.format(product_image_feature_file_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: prepare text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descriptions(descriptions):\n",
    "    \"\"\"\n",
    "    https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/\n",
    "    - Convert all words to lowercase.\n",
    "    - Remove all punctuation.\n",
    "    - Remove all words that are one character or less in length (e.g. ‘a’).\n",
    "    - Remove all words with numbers in them.\n",
    "    \"\"\"\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for key, desc in descriptions.items():\n",
    "        # tokenize\n",
    "        desc = desc.split()\n",
    "        # convert to lower case\n",
    "        desc = [word.lower() for word in desc]\n",
    "        # remove punctuation from each token\n",
    "        desc = [w.translate(table) for w in desc]\n",
    "        # remove hanging 's' and 'a'\n",
    "        desc = [word for word in desc if len(word) > 1]\n",
    "        # remove tokens with numbers in them\n",
    "        desc = [word for word in desc if word.isalpha()]\n",
    "        # store as string\n",
    "        clean_str = ' '.join(desc)\n",
    "        if not clean_str:\n",
    "            print('cleaned description of product {} is empty'.format(key))\n",
    "        else:\n",
    "            descriptions[key] = clean_str\n",
    "\n",
    "\n",
    "product_description_file_path = 'product-descriptions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
